{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyEmma Featurizer Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import openpathsampling as paths\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! lazy\n",
    "import pyemma.coordinates as coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Open existing netCDF file 'engine_store_test.nc' for reading - reading from existing file\n"
     ]
    }
   ],
   "source": [
    "#! lazy\n",
    "ref_storage = paths.Storage('engine_store_test.nc', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Create new netCDF file 'delete.nc' for writing - deleting existing file\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Setup netCDF file and create variables\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'trajectories'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'topologies'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'cvs'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'snapshots'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'samples'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'samplesets'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'pathmovechanges'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'steps'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'details'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'pathmovers'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'shootingpointselectors'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'engines'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'pathsimulators'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'transitions'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'networks'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'schemes'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'interfacesets'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'volumes'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'ensembles'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'tag'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Finished setting up netCDF file\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'snapshot0'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'snapshot0statics'\n",
      "03-08-16 13:18:42 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'snapshot0kinetics'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UUID('e1a53e23-58b2-11e6-8656-000000000014')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! lazy\n",
    "storage = paths.Storage('delete.nc', 'w')\n",
    "storage.trajectories.save(ref_storage.trajectories[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a PyEmma Coordinates Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using of pyemma featurizers or general other complex code requires a little trick to be storable. Since storing of code only works if we are not dependend on the context (scope) we need to wrap the construction of our featurizer in a function, that gets all it needs from the global scope as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pyemma_generator(f):\n",
    "    f.add_inverse_distances(f.pairs(f.select_Backbone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = paths.collectivevariable.PyEMMAFeaturizerCV(\n",
    "    'pyemma', \n",
    "    pyemma_generator, \n",
    "    topology=ref_storage.snapshots[0].topology\n",
    ").with_diskcache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this featurizer generating function to build a collective variable out of it. All we need for that is a name as usual, the generating function, the list of parameters - here only the topology and at best a test snapshot, a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv(ref_storage.trajectories[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save it to the storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(store.cvs[CollectiveVariable], 2, UUID('07f69605-596c-11e6-9658-0000000000ac'))\n"
     ]
    }
   ],
   "source": [
    "#! lazy\n",
    "print storage.save(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and apply the featurizer to a trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv(storage.trajectories[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sync to make sure the cache is written to the netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv(storage.snapshots.all());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py_cv = storage.cvs['pyemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store = storage.stores['cv%d' % storage.idx(py_cv)]\n",
    "nc_var = store.variables['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "assert(nc_var.shape[1] == 15)\n",
    "print nc_var.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy.float32\n"
     ]
    }
   ],
   "source": [
    "assert(nc_var.var_type == 'numpy.float32')\n",
    "print nc_var.var_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ u'{\"_cls\": \"PyEMMAFeaturizerCV\", \"_dict\": {\"topology\": {\"_obj\": \"topologies\", \"_uuid\": \"e1a53e23-58b2-11e6-8656-000000000002\"}, \"name\": \"pyemma\", \"featurizer\": {\"_marshal\": \"YwEAAAABAAAAAwAAAEMAAABzIAAAAHwAAGoAAHwAAGoBAHwAAGoCAIMAAIMBAIMBAAFkAABTKAEAAABOKAMAAAB0FQAAAGFkZF9pbnZlcnNlX2Rpc3RhbmNlc3QFAAAAcGFpcnN0DwAAAHNlbGVjdF9CYWNrYm9uZSgBAAAAdAEAAABmKAAAAAAoAAAAAHMeAAAAPGlweXRob24taW5wdXQtNS00Nzc0ZDhlZGRkMDA+dBAAAABweWVtbWFfZ2VuZXJhdG9yAQAAAHMCAAAAAAE=\", \"_module_vars\": [], \"_global_vars\": []}, \"kwargs\": {}}}']\n"
     ]
    }
   ],
   "source": [
    "#! ignore\n",
    "print storage.variables['cvs_json'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "py_cv_idx = storage.idx(py_cv)\n",
    "print py_cv_idx\n",
    "py_emma_feat = storage.vars['cvs_json'][py_cv_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "erg = py_emma_feat(storage.snapshots);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.68972969  2.06547379]\n",
      " [ 2.61396885  2.00944018]\n",
      " [ 2.73087001  2.06900215]\n",
      " [ 2.79462361  2.09850192]]\n"
     ]
    }
   ],
   "source": [
    "#! lazy\n",
    "print erg[0::5,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "storage.close()\n",
    "ref_storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-08-16 13:18:54 openpathsampling.netcdfplus.netcdfplus INFO     Open existing netCDF file 'delete.nc' for reading - reading from existing file\n"
     ]
    }
   ],
   "source": [
    "#! lazy\n",
    "storage = paths.Storage('delete.nc', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = storage.cvs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that we get the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert np.allclose(erg, cv(storage.snapshots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
